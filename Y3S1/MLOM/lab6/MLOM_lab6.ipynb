{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "s_yoKDuTb17F"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense                #final layers to predict next word\n",
        "from keras.layers import Dropout              #to prevent overfit\n",
        "from keras.layers import LSTM                 #type of RNN to keep long term memory\n",
        "from keras.callbacks import ModelCheckpoint   #to save model\n",
        "from keras.utils import to_categorical     #to utility function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "gH2Y2k3Qb258"
      },
      "outputs": [],
      "source": [
        "filename = \"/content/drive/MyDrive/Practical Materials - Lab 6/data.txt\"\n",
        "raw_text = open(filename,'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "gIYKasQ1h9AT",
        "outputId": "7748fef2-23e7-476c-93c6-2e5330112180"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"project gutenberg's alice's adventures in wonderland, by lewis carroll\\n\\nthis ebook is for the use of\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "raw_text[0:100]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "rMQXVk5UitRh"
      },
      "outputs": [],
      "source": [
        "#create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i,c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EmqYBu-qi1d_",
        "outputId": "199407e6-f18a-4811-aa0e-2c768d60ca19"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'\\n': 0, ' ': 1, '!': 2, '\"': 3, '#': 4, '$': 5, '%': 6, \"'\": 7, '(': 8, ')': 9, '*': 10, ',': 11, '-': 12, '.': 13, '/': 14, '0': 15, '1': 16, '2': 17, '3': 18, '4': 19, '5': 20, '6': 21, '7': 22, '8': 23, '9': 24, ':': 25, ';': 26, '?': 27, '@': 28, '[': 29, ']': 30, '_': 31, 'a': 32, 'b': 33, 'c': 34, 'd': 35, 'e': 36, 'f': 37, 'g': 38, 'h': 39, 'i': 40, 'j': 41, 'k': 42, 'l': 43, 'm': 44, 'n': 45, 'o': 46, 'p': 47, 'q': 48, 'r': 49, 's': 50, 't': 51, 'u': 52, 'v': 53, 'w': 54, 'x': 55, 'y': 56, 'z': 57}\n"
          ]
        }
      ],
      "source": [
        "print(char_to_int)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z3d1EAcji7fw",
        "outputId": "0c2b72a0-5047-4ae0-c37f-822130e38b00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Characters:  163780\n",
            "Total Vocab:  58\n"
          ]
        }
      ],
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"Total Vocab: \", n_vocab)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7XRa8Cwi8EQ",
        "outputId": "f969b584-de01-477a-a545-1dc2685ce1e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Patterns:  163680\n"
          ]
        }
      ],
      "source": [
        "#prepare the dataset of input to output pairs encode as integers\n",
        "seq_length = 100 #can be changed\n",
        "dataX = []\n",
        "dataY = []\n",
        "\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fCc10nFvi8RQ",
        "outputId": "e7e12259-f9db-41a8-82b1-de3ebb043ba6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[1, 39, 36, 43, 47, 1, 47, 49, 46, 35, 52, 34, 36, 1, 46, 52, 49, 1, 45, 36, 54, 1, 36, 33, 46, 46, 42, 50, 11, 1, 32, 45, 35, 1, 39, 46, 54, 1, 51, 46, 0, 50, 52, 33, 50, 34, 49, 40, 33, 36, 1, 51, 46, 1, 46, 52, 49, 1, 36, 44, 32, 40, 43, 1, 45, 36, 54, 50, 43, 36, 51, 51, 36, 49, 1, 51, 46, 1, 39, 36, 32, 49, 1, 32, 33, 46, 52, 51, 1, 45, 36, 54, 1, 36, 33, 46, 46, 42, 50, 13]\n",
            "0\n"
          ]
        }
      ],
      "source": [
        "#checking dataX and dataY\n",
        "print(dataX[163679])\n",
        "print(dataY[163679])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "6Du08sCci8lo"
      },
      "outputs": [],
      "source": [
        "#reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "#normalize\n",
        "X = X / float(n_vocab)\n",
        "#one hot encode the output variable\n",
        "y = to_categorical(dataY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "109PtQNTolS_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "29a5ebbd-3aa1-43b3-fe8c-6cb062b65f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/rnn/rnn.py:204: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(**kwargs)\n"
          ]
        }
      ],
      "source": [
        "#define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))  # (timesteps, features)\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(n_vocab, activation='softmax'))  # n_vocab for vocabulary size\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "#define the checkpoint to save only weights\n",
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.weights.h5\"  # .weights.h5 extension for weights\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, save_weights_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "9gcj6BQlo3oC"
      },
      "outputs": [],
      "source": [
        "#change the hyperparameter values and train the model\n",
        "epochs = 10\n",
        "batch_size = 128"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cn8l7c6-pPmQ",
        "outputId": "a8a35ba0-6c57-4b0a-b9e1-ed693b5123c1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "\u001b[1m1278/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 3.0685\n",
            "Epoch 1: loss improved from inf to 2.97283, saving model to weights-improvement-01-2.9728.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 13ms/step - loss: 3.0684\n",
            "Epoch 2/10\n",
            "\u001b[1m1276/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.8259\n",
            "Epoch 2: loss improved from 2.97283 to 2.79729, saving model to weights-improvement-02-2.7973.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 13ms/step - loss: 2.8258\n",
            "Epoch 3/10\n",
            "\u001b[1m1277/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.7307\n",
            "Epoch 3: loss improved from 2.79729 to 2.71855, saving model to weights-improvement-03-2.7185.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 2.7307\n",
            "Epoch 4/10\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.6613\n",
            "Epoch 4: loss improved from 2.71855 to 2.64887, saving model to weights-improvement-04-2.6489.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - loss: 2.6613\n",
            "Epoch 5/10\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.6065\n",
            "Epoch 5: loss improved from 2.64887 to 2.58808, saving model to weights-improvement-05-2.5881.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 2.6065\n",
            "Epoch 6/10\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.5409\n",
            "Epoch 6: loss improved from 2.58808 to 2.53049, saving model to weights-improvement-06-2.5305.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 14ms/step - loss: 2.5409\n",
            "Epoch 7/10\n",
            "\u001b[1m1278/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4839\n",
            "Epoch 7: loss improved from 2.53049 to 2.47924, saving model to weights-improvement-07-2.4792.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 2.4839\n",
            "Epoch 8/10\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.4406\n",
            "Epoch 8: loss improved from 2.47924 to 2.42931, saving model to weights-improvement-08-2.4293.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - loss: 2.4406\n",
            "Epoch 9/10\n",
            "\u001b[1m1276/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - loss: 2.3895\n",
            "Epoch 9: loss improved from 2.42931 to 2.38690, saving model to weights-improvement-09-2.3869.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 14ms/step - loss: 2.3895\n",
            "Epoch 10/10\n",
            "\u001b[1m1278/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - loss: 2.3479\n",
            "Epoch 10: loss improved from 2.38690 to 2.34669, saving model to weights-improvement-10-2.3467.weights.h5\n",
            "\u001b[1m1279/1279\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 13ms/step - loss: 2.3479\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x79a1b6c97820>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ],
      "source": [
        "model.fit(X, y, epochs=epochs, batch_size=batch_size, callbacks=callbacks_list)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iMkMd-hcD0q7"
      },
      "source": [
        "Generating text with trained LSTM model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "WdvnXL3DpQnB"
      },
      "outputs": [],
      "source": [
        "#Load the network weights\n",
        "import os\n",
        "filename =  \"/content/drive/MyDrive/Practical Materials - Lab 6\"\n",
        "model.save_weights(os.path.join(filename,\"weight-improvement-10-2.3517.weights.h5\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "LYD097ItpQx8"
      },
      "outputs": [],
      "source": [
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "QUTXeYZeFQvP"
      },
      "outputs": [],
      "source": [
        "int_to_char = dict((i,c) for i,c in enumerate(chars))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "VFfiDsOgFQ2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6c7889f3-6b16-4b04-c5ce-cb3e87ec003c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Seed Start Index: 92595\n",
            "Seed Pattern:\n",
            "\" ing to find that the hedgehog had unrolled\n",
            "itself, and was in the act of crawling away: besides all  \"\n"
          ]
        }
      ],
      "source": [
        "#generate a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "print(\"Seed Start Index:\", start)\n",
        "pattern = dataX[start]\n",
        "print(\"Seed Pattern:\")\n",
        "print(\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "1Jo4rbRmFQ7G",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ea7c9bd-4413-47c0-ad05-3a3d908458c9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[40,\n",
              " 45,\n",
              " 38,\n",
              " 1,\n",
              " 51,\n",
              " 46,\n",
              " 1,\n",
              " 37,\n",
              " 40,\n",
              " 45,\n",
              " 35,\n",
              " 1,\n",
              " 51,\n",
              " 39,\n",
              " 32,\n",
              " 51,\n",
              " 1,\n",
              " 51,\n",
              " 39,\n",
              " 36,\n",
              " 1,\n",
              " 39,\n",
              " 36,\n",
              " 35,\n",
              " 38,\n",
              " 36,\n",
              " 39,\n",
              " 46,\n",
              " 38,\n",
              " 1,\n",
              " 39,\n",
              " 32,\n",
              " 35,\n",
              " 1,\n",
              " 52,\n",
              " 45,\n",
              " 49,\n",
              " 46,\n",
              " 43,\n",
              " 43,\n",
              " 36,\n",
              " 35,\n",
              " 0,\n",
              " 40,\n",
              " 51,\n",
              " 50,\n",
              " 36,\n",
              " 43,\n",
              " 37,\n",
              " 11,\n",
              " 1,\n",
              " 32,\n",
              " 45,\n",
              " 35,\n",
              " 1,\n",
              " 54,\n",
              " 32,\n",
              " 50,\n",
              " 1,\n",
              " 40,\n",
              " 45,\n",
              " 1,\n",
              " 51,\n",
              " 39,\n",
              " 36,\n",
              " 1,\n",
              " 32,\n",
              " 34,\n",
              " 51,\n",
              " 1,\n",
              " 46,\n",
              " 37,\n",
              " 1,\n",
              " 34,\n",
              " 49,\n",
              " 32,\n",
              " 54,\n",
              " 43,\n",
              " 40,\n",
              " 45,\n",
              " 38,\n",
              " 1,\n",
              " 32,\n",
              " 54,\n",
              " 32,\n",
              " 56,\n",
              " 25,\n",
              " 1,\n",
              " 33,\n",
              " 36,\n",
              " 50,\n",
              " 40,\n",
              " 35,\n",
              " 36,\n",
              " 50,\n",
              " 1,\n",
              " 32,\n",
              " 43,\n",
              " 43,\n",
              " 1]"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "pattern"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "nJgn3LdDFQ-J",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5713db58-b859-411b-cbc0-64722e3d5843"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['t', 'h', 'e', ' ', 'w', 'o', 'i', 'l', 'e', ' ', 't', 'h', 'e', ' ', 'w', 'a', 'i', ' ', 'i', 'o', 't', ' ', 't', 'o', ' ', 't', 'h', 'e', ' ', 't', 'o', 'i', 'e', 'e', ' ', 't', 'h', ' ', 't', 'h', 'e', ' ', 'c', 'a', 'r', ' ', 'h', 'f', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', ' ', 'o', 'f', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', 'e', ' ', 't', 'h', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', 'e', ' ', 't', 'h', ' ', 't', 'h', 'e', ' ', 'c', 'o', 'u', 'r', 'd', ' ', 't', 'h', ' ']\n"
          ]
        }
      ],
      "source": [
        "#generate characters\n",
        "length = 100\n",
        "final = []\n",
        "\n",
        "for i in range(length):\n",
        "  # reshaping the seed sequence before passing it into the LSTM model\n",
        "  x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "  # normalizing the integer value\n",
        "  x = x / float(n_vocab)\n",
        "  # making prediction\n",
        "  prediction = model.predict(x, verbose=0)\n",
        "  #get the predicted value with maximum probability\n",
        "  index = numpy.argmax(prediction)\n",
        "  #get the predicted integer to char\n",
        "  result = int_to_char[index]\n",
        "  final.append(result)\n",
        "  # adding the predicted character to the sequence\n",
        "  pattern.append(index)\n",
        "  # removing the first character from the sequence\n",
        "  pattern = pattern[1:len(pattern)]\n",
        "print(final)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gyXxcBwJ_e1s"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}